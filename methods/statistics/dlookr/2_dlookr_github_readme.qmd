---
title: "2_dlookr_github_readme"
format: html
editor: visual
---

tidy framework

```{r}
library(dlookr)
browseVignettes(package = "dlookr")  # 网页教程
```

部分readme教程学习：

# 1.Data quality diagnosis

Data: nycflights13

To illustrate basic use of the dlookr package, use the flights data from the nycflights13 package. Once loading nycflights13 library, the flights data frame is available. The flights data frame contains departure and arrival information on all flights departing from NYC(i.e. JFK, LGA or EWR) in 2013.

```{r}
library(nycflights13)
dim(flights)
flights
```

## 1.1 General diagnosis of all variables with diagnose()

### 1.1.1 diagnose()

`diagnose()` allows you to diagnose variables on a data frame. Like any other dplyr functions, the first argument is the tibble (or data frame). The second and subsequent arguments refer to variables within the data frame.

The variables of the tbl_df object returned by diagnose () are as follows.

-   `variables` : variable names
-   `types` : the data type of the variables
-   `missing_count` : number of missing values
-   `missing_percent` : percentage of missing values
-   `unique_count` : number of unique values
-   `unique_rate` : rate of unique value. unique_count / number of observation

For example, we can diagnose all variables in flights:

```{r}
library(dplyr)
library(dlookr)

diagnose(flights)
```

一些数据处理中常见的清洗标准，略

we can diagnose only a few selected variables:

```{r}
diagnose(flights, year, month, day)  # dplyr 形式
```

By using with dplyr, variables including missing values can be sorted by the weight of missing values.:

可联系tidyverse学习笔记

```{r}
flights %>%
  diagnose() %>%
  select(-unique_count, -unique_rate) %>% 
  filter(missing_count > 0) %>% 
  arrange(desc(missing_count))
```

### 1.1.2 Diagnosis of numeric variables with `diagnose_numeric`

diagnose_numeric() diagnoses numeric(continuous and discrete) variables in a data frame. **Usage is the same as diagnose() but returns more diagnostic information.** However, if you specify a non-numeric variable in the second and subsequent argument list, the variable is automatically ignored.

The variables of the tbl_df object returned by diagnose_numeric() are as follows.

-   min : minimum value
-   Q1 : 1/4 quartile, 25th percentile
-   mean : arithmetic mean
-   median : median, 50th percentile
-   Q3 : 3/4 quartile, 75th percentile
-   max : maximum value
-   zero : number of observations with a value of 0
-   minus : number of observations with negative numbers
-   outlier : number of outliers

```{r}
summary(flights$dep_delay)
```

summary{base} 区别于summarise{dplyr}描述汇总函数

The summary() function summarizes the distribution of individual variables in the data frame and outputs it to the console. The summary values of numeric variables are min, Q1, mean, median, Q3 and max, which help to understand the distribution of data.

**However, the result displayed on the console has the disadvantage that the analyst has to look at it with the eyes. However, when the summary information is returned in a data frame structure such as tbl_df, the scope of utilization is expanded.** diagnose_numeric() supports this.

可以直接调用

`zero`, `minus`, and `outlier` are useful measures to diagnose data integrity. For example, numerical data in some cases cannot have zero or negative numbers. A numeric variable called employee salary cannot have negative numbers or zeros. Therefore, this variable should be checked for the inclusion of zero or negative numbers in the data diagnosis process.

diagnose_numeric() can diagnose all numeric variables of flights as follows.:

```{r}
diagnose_numeric(flights)
```

一些数据处理中常见的清洗标准,如 If a numeric variable can not logically have a negative or zero value, it can be used with filter() to easily find a variable that does not logically match:

```{r}
diagnose_numeric(flights) %>% 
  filter(minus > 0 | zero > 0) 
```

### 1.1.3 Diagnosis of categorical variables with `diagnose_category()`

diagnose_category() diagnoses the categorical(factor, ordered, character) variables of a data frame. **The usage is similar to diagnose() but returns more diagnostic information.** If you specify a non-categorical variable in the second and subsequent argument list, the variable is automatically ignored.

The top argument specifies the number of levels to return for each variable. The default is 10, which returns the top 10 level. Of course, if the number of levels is less than 10, all levels are returned.

The variables of the tbl_df object returned by diagnose_category() are as follows.

-   variables : variable names
-   levels: level names
-   N : number of observation
-   freq : number of observation at the levels
-   ratio : percentage of observation at the levels
-   rank : rank of occupancy ratio of levels

`diagnose_category()` can diagnose all categorical variables of flights as follows.:

```{r}
diagnose_category(flights)
```

一些数据处理中常见的清洗标准,略

### 1.1.4 Diagnosing outliers with diagnose_outlier()

diagnose_outlier() diagnoses the outliers of the numeric (continuous and discrete) variables of the data frame. The usage is the same as diagnose().

The variables of the tbl_df object returned by diagnose_outlier() are as follows.

-   outliers_cnt : number of outliers
-   outliers_ratio : percent of outliers
-   outliers_mean : arithmetic average of outliers
-   with_mean : arithmetic average of with outliers
-   without_mean : arithmetic average of without outliers

diagnose_outlier() can diagnose outliers of all numerical variables on flights as follows:

```{r}
diagnose_outlier(flights)
```

一些数据处理中常见的清洗标准,略

1.  排序方法：最常用的方法是计算数据的标准差，并将标准差的倍数作为阈值来识别离群值，通常将3倍标准差及以上的数据视为离群值。

2.  数据可视化方法：使用箱线图或散点图等数据可视化工具，可以帮助快速识别出离群值，并对数据分布情况进行直观的分析。

3.统计测试方法：比如Z分数统计检验，通过计算每个数据点的Z分数，可以判断该数据点与样本中其他点的相对位置，从而识别离群点。

4.  四分位数方法：使用四分位数和箱线图来判断离群值，其中箱线的边界通常是由数据的25th百分位数和75th百分位数确定的。

5.  分段方法：将数据分成多个子组，再对每个子组进行分析，如果某个子组中的数据点比其他子组中的点显著不同，那么该子组中的点可能是离群点.

6.  聚类分析方法：使用聚类分析技术来将数据点分组，并识别与其他数据点显著不同的群组，可以用来识别离群点。

以上这些方法都有其优点和缺点，需要根据不同的情况和数据分析需要来选择合适的方法。

### 1.1.5 Visualization of outliers using plot_outlier()

plot_outlier() visualizes outliers of numerical variables(continuous and discrete) of data.frame. Usage is the same diagnose().

The plot derived from the numerical data diagnosis is as follows.

-   With outliers box plot
-   Without outliers box plot
-   With outliers histogram
-   Without outliers histogram

The following example uses diagnose_outlier(), plot_outlier(), and dplyr packages to visualize all numerical variables with an outlier ratio of 0.5% or higher.

```{r}
flights %>%
  plot_outlier(diagnose_outlier(flights) %>% 
                 filter(outliers_ratio >= 0.5) %>% 
                 select(variables) %>% 
                 unlist())
```

注意函数括号

Looking at the results of the visualization, `arr_delay` shows that the observed values without outliers are similar to the normal distribution. In the case of a linear model, we might consider removing or imputing outliers. And `air_time`has a similar shape before and after removing outliers.

# 2.Exploratory Data Analysis(EDA)

To illustrate the basic use of EDA in the dlookr package, I use a `Carseats` dataset. `Carseats` in the `ISLR` package is a simulated data set containing sales of child car seats at 400 different stores. This data is a data.frame created for the purpose of predicting sales volume.

```{r}
library(ISLR)
str(Carseats)
```

When data analysis is performed, data containing missing values is frequently encountered. However, 'Carseats' is complete data without missing values. So the following script created the missing values and saved them as carseats.

```{r}
carseats <- ISLR::Carseats

suppressWarnings(RNGversion("3.5.0"))
set.seed(123)
carseats[sample(seq(NROW(carseats)), 20), "Income"] <- NA

suppressWarnings(RNGversion("3.5.0"))
set.seed(456)
carseats[sample(seq(NROW(carseats)), 10), "Urban"] <- NA
```

## 2.1 Univariate data EDA

### 2.1.1 Calculating descriptive statistics using describe()

describe() computes descriptive statistics for numerical data. The descriptive statistics help determine the distribution of numerical variables. **Like function of dplyr, the first argument is the tibble (or data frame). The second and subsequent arguments refer to variables within that data frame.**

The variables of the tbl_df object returned by describe() are as follows.

-   n : number of observations excluding missing values
-   na : number of missing values
-   mean : arithmetic average
-   sd : standard deviation
-   se_mean : standard error mean. sd/sqrt(n)
-   IQR : interquartile range (Q3-Q1)
-   skewness : skewness
-   kurtosis : kurtosis
-   p25 : Q1. 25% percentile
-   p50 : median. 50% percentile
-   p75 : Q3. 75% percentile
-   p01, p05, p10, p20, p30 : 1%, 5%, 20%, 30% percentiles
-   p40, p60, p70, p80 : 40%, 60%, 70%, 80% percentiles
-   p90, p95, p99, p100 : 90%, 95%, 99%, 100% percentiles

Skewness是偏度，它用于描述数据分布的非对称性，或者更准确地说，是数据集在中心点左右对称程度的缺失程度。如果一个分布或数据集在中心点左右看起来一样，那么它就是对称分布，偏度就是0；否则，数据集就具有偏态，偏度就不为0。

Kurtosis是峰度，它用于描述数据相对于正态分布的尾部浓度或轻度程度。具有高峰度的数据集往往有重尾部或离群值，而具有低峰度的数据集则往往成为轻尾部或缺乏离群值。一个均匀分布则是极端情况。

For example, we can computes the statistics of all numerical variables in carseats:

```{r}
describe(carseats)
```

`skewness` : The left-skewed distribution data that is the variables with large positive skewness should consider the log or sqrt transformations to follow the normal distribution. The variables `Advertising` seem to need to consider variable transformation.

一些数据处理中常见的分析,略

### 2.1.2 Test of normality on numeric variables using normality()

`normality()`performs a normality test on numerical data. **Shapiro-Wilk normality test is performed. When the number of observations is greater than 5000, it is tested after extracting 5000 samples by random simple sampling.**

> 联系 6.生新技能树生物统计 等

The variables of tbl_df object returned by normality() are as follows.

-   statistic : Statistics of the Shapiro-Wilk test
-   p_value : p-value of the Shapiro-Wilk test
-   sample : Number of sample observations performed Shapiro-Wilk test

normality() performs the normality test for all numerical variables of carseats as follows.:

```{r}
normality(carseats)
```

You can use dplyr to sort variables that do not follow a normal distribution in order of p_value:

```{r}
carseats %>%
  normality() %>%
  filter(p_value <= 0.01) %>% 
  arrange(abs(p_value))
```

In particular, the `Advertising` variable is considered to be the most out of the normal distribution.

The `normality()` function supports the `group_by()` function syntax in the dplyr package.

```{r}
carseats %>%
  group_by(ShelveLoc, US) %>%
  normality(Income) %>% 
  arrange(desc(p_value))
```

The Income variable does not follow the normal distribution. However, the case where US is No and ShelveLoc is Good and Bad at the significance level of 0.01, it follows the normal distribution.

> 进一步分层分析

The following example performs normality test of log(Income) for each combination of ShelveLoc and US categorical variables to search for variables that follow the normal distribution.

```{r}
carseats %>%
  mutate(log_income = log(Income)) %>%
  group_by(ShelveLoc, US) %>%
  normality(log_income) %>%
  filter(p_value > 0.01)
```

## 2.2 Visualization of normality of numerical variables using plot_normality()

`plot_normality()` visualizes the normality of numeric data.

The information that plot_normality() visualizes is as follows.

-   Histogram of original data
-   Q-Q plot of original data
-   histogram of log transformed data
-   Histogram of square root transformed data

In the data analysis process, it often encounters numerical data that follows the power-law distribution. Since the numerical data that follows the power-law distribution is converted into a normal distribution by performing the log or sqrt transformation, so draw a histogram of the log and sqrt transformed data.

"Power-law distribution"是一种数学模，也被称为幂律分布，指的是在统计学中，两个量之间的函数关系会导致另一个量与之成幂次方比例的变化，与初值无关。它是一种常见的分布模型，通常被用来描述在某个区间内一些现象的概率密度分布，例如在一个城市内不同人口数量区间的概率密度分布，以及特定经济指标下不同公司收益的概率密度分布。幂律分布常被用于描述一些有重尾特征的数据，例如社交网络上的用户关注量，财富分布等等。通过幂律分布模型，可以更有效地评估和预测具有重尾特征的数据集中的异常值或局部发展趋势。

plot_normality() can also specify several variables like normality() function.

```{r}
# Select columns by name
plot_normality(carseats, Sales, CompPrice)
```

The plot_normality() function also supports the group_by() function syntax in the dplyr package.

```{r}
carseats %>%
  filter(ShelveLoc == "Good") %>%
  group_by(US) %>%
  plot_normality(Income)
```

QQ plot，即量化-量化图，用于检查一组数据是否服从某个理论分布。通常情况下，这种图用于确定一组数据是否符合正态分布。如果数据是正态分布的，则QQ图中的点将位于一条直线上。相反，如果图中的点离一条直线显著偏离，则数据集不太可能符合正态分布。 所以我们可以通过绘制QQ图，来观察数据的正态性: 若观察到点云基本呈一条直线分布，那么可以认为样本数据近似服从正态分布；若呈现出其他形态，可能并不服从正态分布。

## 2.3 EDA of bivariate data

### 2.3.1 Calculation of correlation coefficient using correlate()

`correlate()` calculates the correlation coefficient of all combinations of carseats numerical variables as follows:

```{r}
correlate(carseats)
```

```{r}
# Select columns by name
correlate(carseats, Sales, CompPrice, Income)
```

一些数据处理中常见的分析,略

### 2.3.2 Visualization of the correlation matrix using plot.correlate()

plot.correlate() visualizes the correlation matrix.

```{r}
carseats %>% 
  correlate() %>%
  plot()
```

一些数据处理中常见的分析,略

一般省略掉的时常见过滤、分析、group_by，以dplyr pipeline形式进行

## 2.4 EDA based on target variable

### 2.4.1 Definition of target variable

To perform EDA based on target variable, you need to create a `target_byclass object`. `target_by()` creates a target_by class with an object inheriting data.frame or data.frame. **target_by() is similar to group_by() in dplyr which creates grouped_df. The difference is that you specify only one variable.**

The following is an example of specifying `US` as target variable in `carseats` data.frame.:

```{r}
categ <- target_by(carseats, US)
cargrp <- group_by(carseats, US)
categ; cargrp
```

Based on the given context, the main difference between target_by and grouped_df objects is that target_by objects are specifically created to perform exploratory data analysis (EDA) based on a target variable, whereas grouped_df objects are created using group-by operations to group a data frame by one or more variables.

Additionally, target_by objects inherit data.frame or data.table classes, whereas grouped_df objects have a DataFrameGroupBy class.

Both objects allow for aggregation of data, but target_by objects provide additional functionality for analyzing the relationship between variables and the target variable.

target_by 上述一些特征，加上EDA另外支持的一些功能

### 2.4.2 EDA when target variable is categorical variabl

Let's perform EDA when the target variable is a categorical variable. When the categorical variable US is the target variable, we examine the relationship between the target variable and the predictor.

#### Cases where predictors are numeric variable:

`relate()` shows the relationship between the target variable and the predictor. The following example shows the relationship between Sales and the target variable US. The **predictor Sales is a numeric variable**. In this case, the descriptive statistics are shown for each level of the target variable.

```{r}
# If the variable of interest is a numerical variable
cat_num <- relate(categ, Sales)
cat_num

summary(cat_num)
```

`plot()` visualizes the `relate class object` created by `relate()` as the relationship between the target variable and the predictor variable. The relationship between US and Sales is visualized by **density plot**.

密度分布

```{r}
plot(cat_num)
```

#### Cases where predictors are categorical variable:

The following example shows the relationship between ShelveLoc and the target variable US. **The predictor variable ShelveLoc is a categorical variable.** In this case, it shows the contingency table of two variables. The summary() function performs independence test on the **contingency table**.

```{r}
# If the variable of interest is a categorical variable
cat_cat <- relate(categ, ShelveLoc)
cat_cat
```

```{r}
summary(cat_cat)
```

`plot()` visualizes the relationship between the target variable and the predictor. The relationship between US and ShelveLoc is represented by a **mosaics plot**

```{r}
plot(cat_cat)
```

### 2.4.3 EDA when target variable is numerical variable

Let's perform EDA when the target variable is numeric. When the numeric variable Sales is the target variable, we examine the relationship between the target variable and the predictor.

```{r}
# If the variable of interest is a numerical variable
num <- target_by(carseats, Sales)
```

#### Cases where predictors are numeric variable:

The following example shows the relationship between Price and the target variable Sales. The predictor variable Price is a numeric variable. In this case, it shows the result of a **simple linear model of the target \~ predictor formula.** The summary() function expresses the details of the model.

```{r}
# If the variable of interest is a numerical variable
num_num <- relate(num, Price)
num_num
```

```{r}
summary(num_num)
```

`plot()` visualizes the relationship between the target and predictor variables. The relationship between Sales and Price is visualized with a scatter plot.

The figure on the left shows the scatter plot of Sales and Price and the confidence interval of the regression line and regression line.

The figure on the right shows the relationship between the original data and the predicted values of the linear model as a scatter plot. If there is a linear relationship between the two variables, the scatter plot of the observations converges on the red diagonal line.

```{r}
plot(num_num)
```

#### Cases where predictors are categorical variable:

The following example shows the relationship between ShelveLoc and the target variable Sales. The predictor ShelveLoc is a categorical variable and shows the result of **one-way ANOVA** of target \~ predictor relationship. The results are expressed in terms of ANOVA.

The summary() function shows the regression coefficients for each level of the predictor. In other words, it shows detailed information about simple regression analysis of target \~ predictor relationship.

```{r}
# If the variable of interest is a categorical variable
num_cat <- relate(num, ShelveLoc)
num_cat
```

```{r}
summary(num_cat)
```

`plot()` visualizes the relationship between the target variable and the predictor. The relationship between Sales and ShelveLoc is represented by a **box plot**.

```{r}
plot(num_cat)
```

# 3.Data Transformation

dlookr **imputes missing values and outliers** and **resolves skewed data.**

It also provides the ability to **bin continuous variables as categorical variables.**

Here is a list of the data conversion functions and functions provided by dlookr:

-   `find_na()` finds a variable that contains the missing values variable, and `imputate_na()` imputes the missing values.
-   `find_outliers()` finds a variable that contains the outliers, and `imputate_outlier()` imputes the outlier.
-   `summary.imputation()` and `plot.imputation()` provide information and visualization of the imputed variables.
-   `find_skewness()` finds the variables of the skewed data, and `transform()` performs the resolving of the skewed data.
-   `transform()` also performs standardization of numeric variables.
-   `summary.transform()` and `plot.transform()` provide information and visualization of transformed variables.
-   `binning()` and `binning_by()` convert binational data into categorical data.
-   `print.bins()` and `summary.bins()` show and summarize the binning results.
-   `plot.bins()` and `plot.optimal_bins()` provide visualization of the binning result.
-   `transformation_report()` performs the data transform and reports the result.

> 联系tidyverse

## 3.1 Imputation of missing values

### 3.1.1 imputes the missing value with imputate_na()

`imputate_na()` imputes the missing value contained in the variable.

The predictor with missing values support **both numeric and categorical variables**, and supports the following method.

-   predictor is numerical variable
-   "mean" : arithmetic mean
-   "median" : median
-   "mode" : mode
-   "knn" : K-nearest neighbors
    -   target variable must be specified
-   "rpart" : Recursive Partitioning and Regression Trees
    -   target variable must be specified
-   "mice" : Multivariate Imputation by Chained Equations
    -   target variable must be specified
    -   random seed must be set
-   predictor is categorical variable
-   "mode" : mode
-   "rpart" : Recursive Partitioning and Regression Trees
    -   target variable must be specified
-   "mice" : Multivariate Imputation by Chained Equations
    -   target variable must be specified
    -   random seed must be set

缺失值插补是指用估计值取代缺失值，然后将完整数据集视为估计值是实际观测值的数据集以进行研究或分析。常用的插补方法如下：

1.用平均值、中位数或众数替换缺失的数值型变量。

2.通过建立模型或使用 K 近邻等基于其它变量的插补方法，来推断缺失的数值型变量。

3.使用 MICE（多重插补法）等方法来同时处理多个变量的缺失。

这些插补方法的选择可根据不同数据类型、缺失值的分情况和具体研究目的灵活确定。

In the following example, `imputate_na()` imputes the missing value of `Income`, a numeric variable of carseats, using the "rpart" method. `summary()` summarizes missing value imputation information, and `plot()` visualizes missing information

"rpart"方法指的是递归分割和回归树（Recursive Partitioning and Regression Trees）方法。该方法通过对样本数据的自变量进行递归分割，将数据集划分为子集，并对每个子集进行最优的回归分析，从而完成对目标变量的预测。在数据插补中，"rpart"方法可用于处理含有缺失值的数值型预测变量，通过建立回归模型对缺失值进行预测并插补。其基本思想是以其他自变量值为基础，构建一个回归模型，并利用模型对缺失值进行估计。

```{r}
income <- imputate_na(carseats, Income, US, method = "rpart")
# US target variable must be specified

summary(income)
```

```{r}
plot(income)
```

The following imputes the categorical variable urban by the "mice" method:

```{r}
library(mice)
urban <- imputate_na(carseats, Urban, US, method = "mice")
```

```{r}
summary(urban)
```

```{r}
plot(urban)
```

### 3.1.2 Collaboration with dplyr

The following example imputes the missing value of the Income variable, and then calculates the arithmetic mean for each level of US. In this case, dplyr is used, and it is easily interpreted logically using pipes.

```{r}
# The mean before and after the imputation of the Income variable
carseats %>%
  mutate(Income_imp = imputate_na(carseats, Income, US, method = "knn")) %>%
  group_by(US) %>%
  summarise(orig = mean(Income, na.rm = TRUE),
    imputation = mean(Income_imp))
```

## 3.2 Imputation of outliers

### 3.2.1 imputes thr outliers with imputate_outlier()

imputate_outlier() imputes the outliers value. The predictor with outliers supports **only numeric variables** and supports the following methods.

-   predictor is numerical variable
-   "mean" : arithmetic mean
-   "median" : median
-   "mode" : mode
-   "capping" : Imputate the upper outliers with 95 percentile, and Imputate the bottom outliers with 5 percentile.

imputate_outlier() imputes the outliers with the numeric variable Price as the "capping" method, as follows.

summary() summarizes outliers imputation information, and plot() visualizes imputation information.

```{r}
price <- imputate_outlier(carseats, Price, method = "capping")
```

```{r}
summary(price)
```

```{r}
plot(price)
```

### 3.2.2 Collaboration with dplyr

```{r}
# The mean before and after the imputation of the Price variable
carseats %>%
  mutate(Price_imp = imputate_outlier(carseats, Price, method = "capping")) %>%
  group_by(US) %>%
  summarise(orig = mean(Price, na.rm = TRUE),
    imputation = mean(Price_imp, na.rm = TRUE))
```

## 3.3 Standardization and Resolving Skewness

### 3.3.1 Introduction to the use of transform()

transform() performs data transformation. Only numeric variables are supported, and the following methods are provided.

-   Standardization
    -   "zscore" : z-score transformation. (x - mu) / sigma
    -   "minmax" : minmax transformation. (x - min) / (max - min)
-   Resolving Skewness
    -   "log" : log transformation. log(x)
    -   "log+1" : log transformation. log(x + 1). Used for values that contain 0.
    -   "sqrt" : square root transformation.
    -   "1/x" : 1 / x transformation
    -   "x\^2" : x square transformation
    -   "x\^3" : x\^3 square transformation

### 3.3.2 tandardization with `transform()`

```{r}
carseats %>% 
  select(Income, Sales) %>% 
  boxplot()
```

Use the methods "zscore" and "minmax" to perform standardization.

```{r}
carseats %>% 
  mutate(Income_minmax = transform(carseats$Income, method = "minmax"),
    Sales_minmax = transform(carseats$Sales, method = "minmax")) %>% 
  select(Income_minmax, Sales_minmax) %>% 
  boxplot()
```

### 3.3.3 Resolving Skewness data with transform()

`find_skewness()` searches for variables with skewed data. This function finds data skewed by search conditions and calculates skewness.

```{r}
# find index of skewed variables
find_skewness(carseats)
```

```{r}
# find names of skewed variables
find_skewness(carseats, index = FALSE)
```

```{r}
# compute the skewness
find_skewness(carseats, value = TRUE)
```

```{r}
# compute the skewness & filtering with threshold
find_skewness(carseats, value = TRUE, thres = 0.1)
```

```{r}
hist(carseats$Advertising)
```

**The skewness of Advertising is 0.637. This means that the distribution of data is somewhat inclined to the left.**

So, for normal distribution, use transform() to convert to "log" method as follows. summary() summarizes transformation information, and plot() visualizes transformation information.

```{r}
Advertising_log = transform(carseats$Advertising, method = "log")

summary(Advertising_log)
```

```{r}
plot(Advertising_log)
```

It seems that the raw data contains 0, as there is a -Inf in the log converted value. So this time, convert it to "log+1".

```{r}
Advertising_log <- transform(carseats$Advertising, method = "log+1")

summary(Advertising_log)
```

```{r}
plot(Advertising_log)
```

## 3.4 Binning

### 3.4.1 Binning of individual variables using binning()

binning() transforms a numeric variable into a categorical variable by binning it. The following types of binning are supported.

-   "quantile" : categorize using quantile to include the same frequencies
-   "equal" : categorize to have equal length segments
-   "pretty" : categorized into moderately good segments
-   "kmeans" : categorization using K-means clustering
-   "bclust" : categorization using bagged clustering technique

> 根据数据特征分类，如果有先验知识肯定更好

Here are some examples of how to bin Income using binning().:

```{r}
# Binning the carat variable. default type argument is "quantile"
bin <- binning(carseats$Income)
# Print bins class object
bin
```

```{r}
summary(bin)
```

```{r}
plot(bin)
```

> 发现第三部分数据转化中结果都可以用summary和plot来帮助理解

```{r}
bin <- binning(carseats$Income, nbins = 4,
              labels = c("LQ1", "UQ1", "LQ3", "UQ3"))
bin
```

```{r}
binning(carseats$Income, nbins = 5, type = "equal")
```

```{r}
binning(carseats$Income, nbins = 5, type = "pretty")
```

```{r}
binning(carseats$Income, nbins = 5, type = "kmeans")
```

```{r}
binning(carseats$Income, nbins = 5, type = "bclust")
```

```{r}
# Extract the binned results
extract(bin)
```

### 3.4.2 Collaboration with dplyr

```{r}
carseats %>%
 mutate(Income_bin = binning(carseats$Income) %>% 
                     extract()) %>%
 group_by(ShelveLoc, Income_bin) %>%
 summarise(freq = n()) %>%
 arrange(desc(freq)) %>%
 head(10)
```

### 3.4.3 Optimal Binning with binning_by()

`binning_by()` transforms a numeric variable into a categorical variable by optimal binning. This method is often used when developing a **scorecard model**.

The following binning_by() example optimally binning Advertising considering the target variable US with a binary class.

```{r}
# optimal binning using character
bin <- binning_by(carseats, "US", "Advertising")

bin
```

```{r}
summary(bin)
```

```{r}
plot(bin)
```

```{r}
extract(bin)
```

# 4.Reporting

## 4.1 Diagnostic Report

dlookr provides two automated data diagnostic reports:

-   Web page-based **dynamic** reports can perform in-depth analysis through visualization and statistical tables.
-   **Static** reports generated as pdf files or html files can be archived as output of data analysis.

### 4.1.1 Create a diagnostic report using diagnose_web_report()

`diagnose_web_report()` create dynamic report for object inherited from data.frame(tbl_df, tbl, etc) or data.frame.

#### Contents of dynamic web report:

-   Overview
    -   Data Structures
        -   Data Structures
        -   Data Types
        -   Job Informations
    -   Warnings
    -   Variables
-   Missing Values
    -   List of Missing Values
    -   Visualization
-   Unique Values
    -   Categorical Variables
    -   Numerical Variables
-   Outliers
-   Samples
    -   Duplicated
    -   Heads
    -   Tails

#### Some arguments for dynamic web report

-   output_file
    -   name of generated file.
-   output_dir
    -   name of directory to generate report file.
-   title
    -   title of report.
-   subtitle
    -   subtitle of report.
-   author
    -   author of report.
-   title_color
    -   color of title.
-   thres_uniq_cat
    -   threshold to use for "Unique Values - Categorical Variables".
-   thres_uniq_num
    -   threshold to use for "Unique Values - Numerical Variables".
-   logo_img
    -   name of logo image file on top left.
-   create_date
    -   The date on which the report is generated.
-   theme
    -   name of theme for report. support "orange" and "blue".
-   sample_percent
    -   Sample percent of data for performing Diagnosis.

The following script creates a q- uality diagnosis report for the tbl_df class object, fli - ghts.

```{r}
flights %>%
  diagnose_web_report(subtitle = "flights", output_dir = "./", 
                      output_file = "Diagn.html", theme = "blue")
```

> 成功

### 4.1.2 Create a diagnostic report using diagnose_paged_report()

`diagnose_paged_report()` create static report for object inherited from data.frame(tbl_df, tbl, etc) or data.frame.

见(github)\[https://github.com/choonghyunryu/dlookr#data-transformation\]

-   The contents of the report
-   Some arguments for static paged report

The following script creates a quality diagnosis report for the tbl_df class object, flights.

```{r}
flights %>%
  diagnose_paged_report(subtitle = "flights", output_dir = "./",
                        output_file = "Diagn.pdf", theme = "blue")
```

## 4.2 EDA Report

dlookr provides two automated EDA reports:

-   Web page-based dynamic reports can perform in-depth analysis through visualization and statistical tables.
-   Static reports generated as pdf files or html files can be archived as output of data analysis.

### 4.2.1 Create a dynamic report using eda_web_report()

`eda_web_report()` create dynamic report for object inherited from data.frame(tbl_df, tbl, etc) or data.frame.

#### Contents of dynamic web report:

-   Overview
    -   Data Structures
    -   Data Types
    -   Job Informations
-   Univariate Analysis
    -   Descriptive Statistics
    -   Normality Test
-   Bivariate Analysis
    -   Compare Numerical Variables
    -   Compare Categorical Variables
-   Multivariate Analysis
    -   Correlation Analysis
        -   Correlation Matrix
        -   Correlation Plot
-   Target based Analysis
    -   Grouped Numerical Variables
    -   Grouped Categorical Variables
    -   Grouped Correlation

#### Some arguments for dynamic web report

-   target
    -   target variable
-   output_file
    -   name of generated file.
-   output_dir
    -   name of directory to generate report file.
-   title
    -   title of report.
-   subtitle
    -   subtitle of report.
-   author
    -   author of report.
-   title_color
    -   color of title.
-   logo_img
    -   name of logo image file on top left.
-   create_date
    -   The date on which the report is generated.
-   theme
    -   name of theme for report. support "orange" and "blue".
-   sample_percent
    -   Sample percent of data for performing EDA.

The following script creates a EDA report for the data.frame class object, heartfailure.

```{r}
heartfailure %>%
  eda_web_report(target = "death_event", subtitle = "heartfailure", 
                 output_dir = "./", output_file = "EDA.html", theme = "blue")
```

> 竟然成功了。那为什么1\_ 没成功？ 怀疑是参数没设好，推文还是有点问题

### 4.2.2 Create a EDA report using eda_paged_report()

见(github)\[https://github.com/choonghyunryu/dlookr#data-transformation\]

-   The contents of the report
-   Some arguments for static paged report

```{r}
# Error in force(expr) : Failed to generate output in 30 seconds (timeout).
# options(timeout = 999999)  # 无效

# heartfailure %>%
#   eda_paged_report(target = "death_event", subtitle = "heartfailure", 
#                    output_dir = "./", output_file = "EDA.pdf", theme = "blue")
```

## 4.3 Data Transformation Report

dlookr provides two automated data transformation reports:

-   Web page-based dynamic reports can perform in-depth analysis through visualization and statistical tables.
-   Static reports generated as pdf files or html files can be archived as output of data analysis.

### 4.3.1 Create a dynamic report using `transformation_web_report()`

#### Contents of dynamic web report

-   Overview
    -   Data Structures
    -   Data Types
    -   Job Informations
-   Imputation
    -   Missing Values
    -   Outliers
-   Resolving Skewness
-   Binning
-   Optimal Binning

#### Some arguments for dynamic web report

跟前面差不多，略

```{r}
# Error: Package "forecast" needed for this function to work. Please install it.
# install.packages("forecast")
heartfailure %>%
  transformation_web_report(target = "death_event", subtitle = "heartfailure",
                            output_dir = "./", output_file = "transformation.html", 
                            theme = "blue")
```

### 4.3.2 Create a static report using transformation_paged_report()

见(github)\[https://github.com/choonghyunryu/dlookr#data-transformation\]

-   The contents of the report
-   Some arguments for static paged report

The following script creates a data transformation report for the data.frame class object, heartfailure.

```{r}
# Error in force(expr) : Failed to generate output in 30 seconds (timeout).
# heartfailure %>%
#   transformation_paged_report(target = "death_event", subtitle = "heartfailure",
#                               output_dir = "./", output_file = "transformation.pdf", 
#                               theme = "blue")
```

# 5.Supports table of DBMS

DBMS是数据库管理系统（Database Management System）的缩写，是一种管理数据的软件系统，可以处理大规模数据的存储、检索和管理。这种系统允许用户创建、定义、管理和控制数据库中的数据，为用户提供访问和操作数据库的工具。DBMS由数据引擎、数据库管理器和数据库模式三部分构成，其中数据引擎负责数据的访问、锁定和修改，数据库管理器控制数据库中的数据，数据库模式定义了数据库的逻辑结构。DBMS还能够通过内部或外部接口，与其他应用程序或系统进行交互。

略

------------------------------------------------------------------------

3\_

根据另一篇推文进行学习，更好地解读结果

(用dlookr包对数据进行诊断、探索和修复（探索性数据分析）)\[https://mp.weixin.qq.com/s/tqwT-tULD3X8Y-hmRt5g2Q\]
